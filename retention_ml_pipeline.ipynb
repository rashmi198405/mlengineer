{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87fbe5d4",
   "metadata": {},
   "source": [
    "# Customer Retention ML Pipeline with SageMaker Feature Store\n",
    "\n",
    "This notebook implements a complete machine learning pipeline for customer retention prediction using Amazon SageMaker Feature Store and XGBoost. The pipeline includes:\n",
    "\n",
    "1. Data retrieval from Feature Store\n",
    "2. Data preprocessing and feature engineering\n",
    "3. Model training with XGBoost\n",
    "4. Model evaluation and deployment\n",
    "5. Model monitoring setup\n",
    "\n",
    "## Requirements\n",
    "- AWS SageMaker access\n",
    "- Required Python packages (boto3, sagemaker, pandas, numpy, scikit-learn, etc.)\n",
    "- Configured AWS credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d4ec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker.xgboost.model import XGBoostModel\n",
    "from sagemaker.tuner import HyperparameterTuner, IntegerParameter, ContinuousParameter\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sagemaker\n",
    "import io\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cb6e4b",
   "metadata": {},
   "source": [
    "## SageMaker Setup\n",
    "\n",
    "Initialize the SageMaker session and get the execution role. This section sets up the basic AWS resources needed for the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be20468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SageMaker session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "#role = get_execution_role()\n",
    "role = 'arn:aws:iam::269031123124:role/service-role/AmazonSageMaker-ExecutionRole-20250629T210810'\n",
    "region = sagemaker_session.boto_region_name\n",
    "s3_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print(f\"Role: {role}\")\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"S3 Bucket: {s3_bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdbbe47",
   "metadata": {},
   "source": [
    "## Data Retrieval from Feature Store\n",
    "\n",
    "Connect to the Feature Store and retrieve the customer data. The Feature Store provides a centralized repository for feature management and ensures consistent feature access across training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55634acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Feature Group\n",
    "feature_group_name = 'rcp'  \n",
    "feature_group = FeatureGroup(name=feature_group_name, sagemaker_session=sagemaker_session)\n",
    "\n",
    "# Query data from Feature Store\n",
    "query_string = f\"\"\"\n",
    "SELECT *\n",
    "FROM \"{feature_group_name}\"\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "query_results = feature_group.athena_query(\n",
    "    query_string=query_string,\n",
    "    output_location=f's3://{s3_bucket}/query_results/'\n",
    ")\n",
    "\n",
    "# Wait for query to complete and get results\n",
    "query_results.wait()\n",
    "df = query_results.as_dataframe()\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36337a79",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Clean and prepare the data for training. This includes:\n",
    "1. Removing metadata columns\n",
    "2. Handling missing values\n",
    "3. Preparing features and target variables\n",
    "4. Splitting data into train, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df807624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove metadata columns\n",
    "feature_columns = [col for col in df.columns if col not in ['write_time', 'api_invocation_time', 'is_deleted']]\n",
    "df_features = df[feature_columns].copy()\n",
    "\n",
    "# Handle missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df_features.isnull().sum())\n",
    "\n",
    "\n",
    "\n",
    "# Prepare features and target\n",
    "feature_cols = [col for col in df_features.columns if col not in ['retained', 'custid']]\n",
    "X = df_features[feature_cols]\n",
    "y = df_features['retained']\n",
    "\n",
    "print(f\"Feature columns: {feature_cols}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts()}\")\n",
    "print(f\"Class distribution percentage:\\n{y.value_counts(normalize=True) * 100}\")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Validation set shape: {X_val.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563ad1ed",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Configure and train the XGBoost model using SageMaker. This section includes:\n",
    "1. Preparing data in SageMaker format\n",
    "2. Setting up the XGBoost estimator\n",
    "3. Configuring hyperparameters\n",
    "4. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa0abf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for XGBoost (target first column)\n",
    "train_data = pd.concat([y_train, X_train], axis=1)\n",
    "val_data = pd.concat([y_val, X_val], axis=1)\n",
    "test_data = pd.concat([y_test, X_test], axis=1)\n",
    "\n",
    "# Save to S3 in CSV format\n",
    "train_path = f's3://{s3_bucket}/customer-retention/train/train.csv'\n",
    "val_path = f's3://{s3_bucket}/customer-retention/validation/validation.csv'\n",
    "test_path = f's3://{s3_bucket}/customer-retention/test/test.csv'\n",
    "\n",
    "train_data.to_csv(train_path, index=False, header=False)\n",
    "val_data.to_csv(val_path, index=False, header=False)\n",
    "test_data.to_csv(test_path, index=False, header=False)\n",
    "\n",
    "print(f\"Training data saved to: {train_path}\")\n",
    "print(f\"Validation data saved to: {val_path}\")\n",
    "print(f\"Test data saved to: {test_path}\")\n",
    "\n",
    "# Create XGBoost estimator using built-in algorithm\n",
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "# Get the XGBoost container image URI\n",
    "container = retrieve('xgboost', region, version='1.5-1')\n",
    "\n",
    "xgb_estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=container,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    output_path=f's3://{s3_bucket}/customer-retention/output',\n",
    "    base_job_name='customer-retention-xgb'\n",
    ")\n",
    "\n",
    "# Set hyperparameters\n",
    "hyperparameters = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc,error',\n",
    "    'num_round': 100,\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.3,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'scale_pos_weight': len(y_train[y_train == 0]) / len(y_train[y_train == 1]),\n",
    "    'early_stopping_rounds': 10,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "xgb_estimator.set_hyperparameters(**hyperparameters)\n",
    "\n",
    "# Create TrainingInput objects\n",
    "train_input = sagemaker.inputs.TrainingInput(train_path, content_type='text/csv')\n",
    "val_input = sagemaker.inputs.TrainingInput(val_path, content_type='text/csv')\n",
    "\n",
    "# Train the model\n",
    "print(\"\\n=== Training XGBoost Model ===\")\n",
    "xgb_estimator.fit({\n",
    "    'train': train_input,\n",
    "    'validation': val_input\n",
    "}, wait=True)\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353868c6",
   "metadata": {},
   "source": [
    "## Model Deployment and Evaluation\n",
    "\n",
    "Deploy the trained model and evaluate its performance on the test set. This section includes:\n",
    "1. Model deployment to an endpoint\n",
    "2. Making predictions on test data\n",
    "3. Calculating performance metrics\n",
    "4. Visualizing results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a50bbe",
   "metadata": {},
   "source": [
    "### Model Deployment\n",
    "\n",
    "Register the trained model in the SageMaker Model Registry and deploy it to a real-time endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65665910",
   "metadata": {},
   "source": [
    "### Model Testing\n",
    "\n",
    "Run comprehensive tests on the deployed endpoint, including single and batch predictions, performance, error handling, and confidence analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b835859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_registry import ModelRegistry\n",
    "from sagemaker.model_package import ModelPackage\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.drift_check_baselines import DriftCheckBaselines\n",
    "import time\n",
    "import json\n",
    "\n",
    "# STEP 1: Model Registration (Add this after model training)\n",
    "print(\"\\n=== Registering Model in SageMaker Model Registry ===\")\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=f's3://{s3_bucket}/customer-retention/model-metrics/statistics.json',\n",
    "        content_type=\"application/json\"\n",
    "    ),\n",
    "    model_constraints=MetricsSource(\n",
    "        s3_uri=f's3://{s3_bucket}/customer-retention/model-metrics/constraints.json',\n",
    "        content_type=\"application/json\"\n",
    "    )\n",
    ")\n",
    "\n",
    "metrics_data = {\n",
    "    \"binary_classification_metrics\": {\n",
    "        \"accuracy\": {\"value\": float(accuracy)},\n",
    "        \"auc_roc\": {\"value\": float(auc_roc)},\n",
    "        \"confusion_matrix\": confusion_matrix(y_test, pred_binary).tolist(),\n",
    "        \"classification_report\": classification_report(y_test, pred_binary, output_dict=True)\n",
    "    }\n",
    "}\n",
    "\n",
    "import boto3\n",
    "s3_client = boto3.client('s3')\n",
    "s3_client.put_object(\n",
    "    Bucket=s3_bucket,\n",
    "    Key='customer-retention/model-metrics/statistics.json',\n",
    "    Body=json.dumps(metrics_data),\n",
    "    ContentType='application/json'\n",
    ")\n",
    "\n",
    "model_package_group_name = \"customer-retention-models\"\n",
    "try:\n",
    "    sagemaker_client = boto3.client('sagemaker')\n",
    "    sagemaker_client.create_model_package_group(\n",
    "        ModelPackageGroupName=model_package_group_name,\n",
    "        ModelPackageGroupDescription=\"Customer retention prediction models\"\n",
    "    )\n",
    "    print(f\"Created model package group: {model_package_group_name}\")\n",
    "except Exception as e:\n",
    "    if \"already exists\" in str(e):\n",
    "        print(f\"Model package group {model_package_group_name} already exists\")\n",
    "    else:\n",
    "        print(f\"Error creating model package group: {e}\")\n",
    "\n",
    "model_package = xgb_estimator.register(\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=\"Approved\",\n",
    "    model_metrics=model_metrics,\n",
    "    description=\"Customer retention prediction model using XGBoost\"\n",
    ")\n",
    "\n",
    "print(f\"Model registered successfully!\")\n",
    "print(f\"Model Package ARN: {model_package.model_package_arn}\")\n",
    "\n",
    "# STEP 2: Deploy Model from Registry (Replace the existing deployment code)\n",
    "print(\"\\n=== Deploying Model from Registry ===\")\n",
    "\n",
    "model_name = f\"customer-retention-model-{int(time.time())}\"\n",
    "endpoint_name = f\"customer-retention-endpoint-{int(time.time())}\"\n",
    "\n",
    "model = ModelPackage(\n",
    "    role=role,\n",
    "    model_package_arn=model_package.model_package_arn,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.t2.medium',\n",
    "    endpoint_name=endpoint_name,\n",
    "    serializer=sagemaker.serializers.CSVSerializer(),\n",
    "    deserializer=sagemaker.deserializers.CSVDeserializer()\n",
    ")\n",
    "\n",
    "print(f\"Model deployed successfully!\")\n",
    "print(f\"Endpoint name: {endpoint_name}\")\n",
    "print(f\"Endpoint ARN: arn:aws:sagemaker:{region}:{sagemaker_session.account_id()}:endpoint/{endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5690ed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Model Testing ===\n",
    "# STEP 3: Comprehensive API Endpoint Testing\n",
    "print(\"\\n=== Testing API Endpoint ===\")\n",
    "\n",
    "# Test 1: Single prediction\n",
    "print(\"\\n1. Single Prediction Test:\")\n",
    "single_sample = X_test.iloc[[0]]\n",
    "single_prediction = predictor.predict(single_sample.values)\n",
    "print(f\"Input features: {single_sample.values[0]}\")\n",
    "print(f\"Prediction: {single_prediction[0]}\")\n",
    "print(f\"Actual: {y_test.iloc[0]}\")\n",
    "\n",
    "# Test 2: Batch prediction\n",
    "print(\"\\n2. Batch Prediction Test:\")\n",
    "batch_size = 10\n",
    "batch_samples = X_test.iloc[:batch_size]\n",
    "batch_predictions = predictor.predict(batch_samples.values)\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Predictions: {batch_predictions}\")\n",
    "print(f\"Actual values: {y_test.iloc[:batch_size].values}\")\n",
    "\n",
    "# Test 3: Performance test\n",
    "print(\"\\n3. Performance Test:\")\n",
    "import time\n",
    "start_time = time.time()\n",
    "performance_samples = X_test.iloc[:100]\n",
    "performance_predictions = predictor.predict(performance_samples.values)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Processed {len(performance_samples)} predictions in {end_time - start_time:.2f} seconds\")\n",
    "print(f\"Average prediction time: {(end_time - start_time) / len(performance_samples) * 1000:.2f} ms per prediction\")\n",
    "\n",
    "# Test 4: Error handling\n",
    "print(\"\\n4. Error Handling Test:\")\n",
    "try:\n",
    "    invalid_input = [[999, 999, 999]]\n",
    "    error_prediction = predictor.predict(invalid_input)\n",
    "    print(f\"Handled invalid input: {error_prediction}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error handling test passed: {str(e)}\")\n",
    "\n",
    "# Test 5: Endpoint health check\n",
    "print(\"\\n5. Endpoint Health Check:\")\n",
    "try:\n",
    "    health_check = predictor.predict(X_test.iloc[[0]].values)\n",
    "    print(\"✅ Endpoint is healthy and responding\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Endpoint health check failed: {e}\")\n",
    "\n",
    "# STEP 4: Detailed API Testing with Different Data Types\n",
    "print(\"\\n=== Advanced API Testing ===\")\n",
    "\n",
    "# Test with edge cases\n",
    "print(\"\\n1. Edge Case Testing:\")\n",
    "edge_cases = [\n",
    "    X_test.min().values.reshape(1, -1),\n",
    "    X_test.max().values.reshape(1, -1),\n",
    "    X_test.mean().values.reshape(1, -1)\n",
    "]\n",
    "\n",
    "for i, case in enumerate(edge_cases):\n",
    "    try:\n",
    "        prediction = predictor.predict(case)\n",
    "        print(f\"Edge case {i+1}: {prediction[0]:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Edge case {i+1} failed: {e}\")\n",
    "\n",
    "# Test prediction confidence\n",
    "print(\"\\n2. Prediction Confidence Analysis:\")\n",
    "confidence_samples = X_test.iloc[:20]\n",
    "confidence_predictions = predictor.predict(confidence_samples.values)\n",
    "confidence_scores = np.array(confidence_predictions).flatten()\n",
    "\n",
    "high_confidence = confidence_scores[(confidence_scores > 0.8) | (confidence_scores < 0.2)]\n",
    "medium_confidence = confidence_scores[(confidence_scores >= 0.2) & (confidence_scores <= 0.8)]\n",
    "\n",
    "print(f\"High confidence predictions (>0.8 or <0.2): {len(high_confidence)}\")\n",
    "print(f\"Medium confidence predictions (0.2-0.8): {len(medium_confidence)}\")\n",
    "\n",
    "# STEP 5: Model Registry Management\n",
    "print(\"\\n=== Model Registry Management ===\")\n",
    "\n",
    "try:\n",
    "    model_packages = sagemaker_client.list_model_packages(\n",
    "        ModelPackageGroupName=model_package_group_name\n",
    "    )\n",
    "    print(f\"Total models in registry: {len(model_packages['ModelPackageSummaryList'])}\")\n",
    "    for pkg in model_packages['ModelPackageSummaryList']:\n",
    "        print(f\"- Model: {pkg['ModelPackageArn']}\")\n",
    "        print(f\"  Status: {pkg['ModelPackageStatus']}\")\n",
    "        print(f\"  Created: {pkg['CreationTime']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error listing model packages: {e}\")\n",
    "\n",
    "print(f\"\\n=== Endpoint Configuration ===\")\n",
    "print(f\"Endpoint Name: {endpoint_name}\")\n",
    "print(f\"Instance Type: ml.t2.medium\")\n",
    "print(f\"Instance Count: 1\")\n",
    "print(f\"Model Package: {model_package.model_package_arn}\")\n",
    "print(f\"Status: InService\")\n",
    "\n",
    "print(\"\\n=== Testing Complete ===\")\n",
    "print(\"✅ Model successfully registered in SageMaker Model Registry\")\n",
    "print(\"✅ Model deployed from registry to endpoint\")\n",
    "print(\"✅ API endpoint tested and validated\")\n",
    "print(\"✅ Ready for production use!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c73c03",
   "metadata": {},
   "source": [
    "## Model Monitoring\n",
    "\n",
    "Set up model monitoring to track the model's performance in production. This section includes:\n",
    "1. Creating a baseline for monitoring\n",
    "2. Setting up monitoring schedule\n",
    "3. Configuring CloudWatch metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31031618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Model Monitor\n",
    "print(\"\\n=== Setting up Model Monitor ===\")\n",
    "\n",
    "# Create baseline dataset\n",
    "baseline_dataset = test_data.copy()\n",
    "baseline_path = f's3://{s3_bucket}/customer-retention/baseline/baseline.csv'\n",
    "baseline_dataset.to_csv(baseline_path, index=False)\n",
    "\n",
    "# Create model monitor\n",
    "model_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    ")\n",
    "\n",
    "# Create baseline\n",
    "baseline_job = model_monitor.suggest_baseline(\n",
    "    baseline_dataset=baseline_path,\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri=f's3://{s3_bucket}/customer-retention/baseline-results',\n",
    "    wait=True\n",
    ")\n",
    "\n",
    "print(\"Baseline created successfully!\")\n",
    "\n",
    "# Create monitoring schedule\n",
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "\n",
    "mon_schedule = model_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=f'customer-retention-monitor',\n",
    "    endpoint_input=predictor.endpoint_name,\n",
    "    output_s3_uri=f's3://{s3_bucket}/customer-retention/monitoring-results',\n",
    "    statistics=baseline_job.baseline_statistics(),\n",
    "    constraints=baseline_job.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.daily(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")\n",
    "\n",
    "print(\"Monitoring schedule created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94db4326",
   "metadata": {},
   "source": [
    "## Cleanup Instructions\n",
    "\n",
    "To avoid unnecessary charges, make sure to clean up the resources when you're done:\n",
    "1. Delete the endpoint\n",
    "2. Stop the monitoring schedule\n",
    "3. Remove unnecessary S3 objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617964d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup resources\n",
    "print(\"To clean up resources, run the following:\")\n",
    "\n",
    "# Delete endpoint\n",
    "print(\"\\n1. Delete the endpoint:\")\n",
    "print(\"predictor.delete_endpoint()\")\n",
    "\n",
    "# Stop monitoring schedule\n",
    "print(\"\\n2. Stop the monitoring schedule:\")\n",
    "print(\"model_monitor.stop_monitoring_schedule()\")\n",
    "\n",
    "# Note about S3 cleanup\n",
    "print(\"\\n3. Remove S3 objects if no longer needed:\")\n",
    "print(f\"aws s3 rm s3://{s3_bucket}/customer-retention/ --recursive\")\n",
    "\n",
    "print(\"\\nIMPORTANT: Only run these commands when you're done with the model!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
